{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6bbd17-300b-4c70-af5e-877681b23e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv genai-fake-article\n",
    "!source genai-fake-article/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef810291-30f6-41d4-8070-9643c67d35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8c0bd9-7abc-4796-b8c7-3b03815e1e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure created successfully!\n"
     ]
    }
   ],
   "source": [
    "# create folder/files structure\n",
    "\n",
    "import os\n",
    "\n",
    "folders = [\n",
    "    'genai-fake-article/data',\n",
    "    'genai-fake-article/models',\n",
    "    'genai-fake-article/scripts',\n",
    "    'genai-fake-article/outputs',\n",
    "]\n",
    "\n",
    "files = [\n",
    "    'genai-fake-article/README.md',\n",
    "    'genai-fake-article/data/arxiv_papers.json',\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for file_path in files:\n",
    "    open(file_path, 'w').close()\n",
    "\n",
    "print(\"Structure created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481affbc-8662-46d5-b767-865f164eeb5c",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e5416d-5c7f-424c-9c3c-ff0c64745c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to genai-fake-article/data/arxiv_papers.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "def fetch_arxiv_papers(query, max_results=100):\n",
    "    # Define the base URL and parameters\n",
    "    base_url = 'http://export.arxiv.org/api/query'\n",
    "    params = {\n",
    "        'search_query': query,\n",
    "        'max_results': max_results,\n",
    "        'start': 0,\n",
    "        'sortBy': 'relevance',\n",
    "        'sortOrder': 'descending'\n",
    "    }\n",
    "    \n",
    "    # Make the request to arXiv API\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Check if the response was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data from arXiv API, status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse the XML response\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    # Extract titles and abstracts\n",
    "    papers = []\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip()\n",
    "        abstract = entry.find('{http://www.w3.org/2005/Atom}summary').text.strip()\n",
    "        papers.append({'title': title, 'abstract': abstract})\n",
    "    \n",
    "    return papers\n",
    "\n",
    "def save_papers_to_json(papers, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(papers, f, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Tests\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"machine learning\"\n",
    "    max_results = 10 \n",
    "    papers = fetch_arxiv_papers(query, max_results)\n",
    "    save_papers_to_json(papers, 'genai-fake-article/data/arxiv_papers.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
